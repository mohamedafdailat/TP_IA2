{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfXBz7EwRZjOmW76WJw967",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedafdailat/TP_IA2/blob/main/TP_IA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyse des données**"
      ],
      "metadata": {
        "id": "eGpLJVAqBxdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Charger les données et afficher les premières lignes**"
      ],
      "metadata": {
        "id": "1PvGdYzHCAlK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlDWXjheBsnz",
        "outputId": "ff75994d-04b6-48ed-d322-7e0cc0589393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
            "0  2024-01-01 00:00:00          NaN        2.58      3.16    11.86   \n",
            "1  2024-01-01 01:00:00        55.60        2.55      3.35    11.97   \n",
            "2  2024-01-01 02:00:00        60.74        1.20      3.20    12.06   \n",
            "3  2024-01-01 03:00:00        66.15        2.67      3.56    12.95   \n",
            "4  2024-01-01 04:00:00        58.16         NaN      4.10    11.25   \n",
            "\n",
            "   Operating_Time  Humidity  Noise_Level  Energy_Consumption   Pump_Type  \\\n",
            "0            0.56     67.93        65.62                0.01      Piston   \n",
            "1            2.04     47.59        70.46                0.01  Centrifuge   \n",
            "2            3.34     56.45        63.46                0.01      Piston   \n",
            "3            4.71     43.62        69.28                0.01  Centrifuge   \n",
            "4            5.90     39.67        67.18                0.01      Piston   \n",
            "\n",
            "  Location  State  \n",
            "0   Zone A      0  \n",
            "1   Zone A      0  \n",
            "2   Zone A      0  \n",
            "3   Zone C      0  \n",
            "4   Zone B      0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le dataset\n",
        "df = pd.read_csv('maintenance_predictive.csv')\n",
        "\n",
        "# Afficher les premières lignes\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identifier les colonnes, types de données et valeurs manquantes**"
      ],
      "metadata": {
        "id": "_7nNY9KtBv2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les informations sur les colonnes et les types de données\n",
        "print(df.info())\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dig4LoFCnl4",
        "outputId": "6dceaedc-d63e-4b5f-a237-8abf4f593920"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 12 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Timestamp           5000 non-null   object \n",
            " 1   Temperature         4750 non-null   float64\n",
            " 2   Vibrations          4750 non-null   float64\n",
            " 3   Pressure            4750 non-null   float64\n",
            " 4   Current             4750 non-null   float64\n",
            " 5   Operating_Time      5000 non-null   float64\n",
            " 6   Humidity            4750 non-null   float64\n",
            " 7   Noise_Level         4750 non-null   float64\n",
            " 8   Energy_Consumption  4750 non-null   float64\n",
            " 9   Pump_Type           5000 non-null   object \n",
            " 10  Location            5000 non-null   object \n",
            " 11  State               5000 non-null   int64  \n",
            "dtypes: float64(8), int64(1), object(3)\n",
            "memory usage: 468.9+ KB\n",
            "None\n",
            "Timestamp               0\n",
            "Temperature           250\n",
            "Vibrations            250\n",
            "Pressure              250\n",
            "Current               250\n",
            "Operating_Time          0\n",
            "Humidity              250\n",
            "Noise_Level           250\n",
            "Energy_Consumption    250\n",
            "Pump_Type               0\n",
            "Location                0\n",
            "State                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculer des statistiques de base**"
      ],
      "metadata": {
        "id": "cyGqS1ZICuEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer des statistiques de base\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDxTxhTdCxFt",
        "outputId": "34ccafd1-2ab7-43e8-9513-8769f39a6fa6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Temperature   Vibrations     Pressure      Current  Operating_Time  \\\n",
            "count  4750.000000  4750.000000  4750.000000  4750.000000     5000.000000   \n",
            "mean     57.254011     3.441402     3.634705    12.343617     2479.450176   \n",
            "std       9.053411     2.288461     0.762451     1.733788     1428.333659   \n",
            "min      35.610000    -0.920000     1.810000     8.140000        0.560000   \n",
            "25%      51.550000     2.350000     3.190000    11.380000     1244.915000   \n",
            "50%      55.855000     3.040000     3.530000    12.070000     2483.700000   \n",
            "75%      60.957500     3.800000     3.900000    12.840000     3714.692500   \n",
            "max      89.970000    14.890000     7.000000    19.990000     4956.740000   \n",
            "\n",
            "          Humidity  Noise_Level  Energy_Consumption        State  \n",
            "count  4750.000000  4750.000000         4750.000000  5000.000000  \n",
            "mean     50.957598    72.306211            0.011158     0.296800  \n",
            "std      10.669382     8.567884            0.003857     0.775648  \n",
            "min      15.050000    47.670000            0.010000     0.000000  \n",
            "25%      43.532500    66.940000            0.010000     0.000000  \n",
            "50%      50.630000    70.670000            0.010000     0.000000  \n",
            "75%      57.787500    74.940000            0.010000     0.000000  \n",
            "max      86.920000    99.950000            0.030000     3.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pré-traitement des données**"
      ],
      "metadata": {
        "id": "azglCVGUDBYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder les variables catégoriques**"
      ],
      "metadata": {
        "id": "nfjDXV3DDCp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoder les variables catégoriques\n",
        "label_encoder = LabelEncoder()\n",
        "df['Pump_Type'] = label_encoder.fit_transform(df['Pump_Type'])\n",
        "df['Location'] = label_encoder.fit_transform(df['Location'])"
      ],
      "metadata": {
        "id": "QlaG08pWDFnD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0AvzcIMHJp8",
        "outputId": "735a4e35-cbe1-487b-b323-5e37b2f61c54"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gérer les données manquantes**"
      ],
      "metadata": {
        "id": "RYtZsfUGDgbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoder les variables catégoriques\n",
        "label_encoder = LabelEncoder()\n",
        "df['Pump_Type'] = label_encoder.fit_transform(df['Pump_Type'])\n",
        "df['Location'] = label_encoder.fit_transform(df['Location'])\n",
        "\n",
        "# Remplacer les valeurs manquantes par la moyenne des colonnes numériques uniquement\n",
        "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQHQ09ccDi0q",
        "outputId": "7acbc5e2-713f-4f77-9d31-3044cfb643c9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
            "0  2024-01-01 00:00:00    57.254011    2.580000      3.16    11.86   \n",
            "1  2024-01-01 01:00:00    55.600000    2.550000      3.35    11.97   \n",
            "2  2024-01-01 02:00:00    60.740000    1.200000      3.20    12.06   \n",
            "3  2024-01-01 03:00:00    66.150000    2.670000      3.56    12.95   \n",
            "4  2024-01-01 04:00:00    58.160000    3.441402      4.10    11.25   \n",
            "\n",
            "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
            "0            0.56     67.93        65.62                0.01          2   \n",
            "1            2.04     47.59        70.46                0.01          0   \n",
            "2            3.34     56.45        63.46                0.01          2   \n",
            "3            4.71     43.62        69.28                0.01          0   \n",
            "4            5.90     39.67        67.18                0.01          2   \n",
            "\n",
            "   Location  State  \n",
            "0         0      0  \n",
            "1         0      0  \n",
            "2         0      0  \n",
            "3         2      0  \n",
            "4         1      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convertir la colonne Timestamp en datetime**"
      ],
      "metadata": {
        "id": "KzHmJDFfEizg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la colonne Timestamp en datetime\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "# Trier les données par Timestamp\n",
        "df.sort_values('Timestamp', inplace=True)"
      ],
      "metadata": {
        "id": "BgohQdatEjyF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normaliser ou standardiser les variables numériques**"
      ],
      "metadata": {
        "id": "XQMD-JZPEwOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normaliser les variables numériques\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['Temperature', 'Vibrations', 'Pressure', 'Current', 'Operating_Time', 'Humidity', 'Noise_Level', 'Energy_Consumption']\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
      ],
      "metadata": {
        "id": "l1T10PL3Exgb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Créer les vecteurs X et Y**"
      ],
      "metadata": {
        "id": "PZfXfQczE45c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer les vecteurs X et Y\n",
        "X = df.drop(columns=['State', 'Timestamp'])\n",
        "Y = df['State']"
      ],
      "metadata": {
        "id": "YIMt8agxE6G8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Créer des séquences temporelles**"
      ],
      "metadata": {
        "id": "g2_-NTlNFERo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(data, target, window_size):\n",
        "    X_seq, Y_seq = [], []\n",
        "    for i in range(len(data) - window_size):\n",
        "        X_seq.append(data[i:i+window_size])\n",
        "        Y_seq.append(target[i+window_size])\n",
        "    return np.array(X_seq), np.array(Y_seq)\n",
        "\n",
        "window_size = 10\n",
        "X_seq, Y_seq = create_sequences(X.values, Y.values, window_size)\n",
        "\n",
        "# Vérifier la taille des séquences\n",
        "print(X_seq.shape, Y_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrloMdHnFFdO",
        "outputId": "dc1d1147-9b50-4e75-c431-36419f8f31ca"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4990, 10, 10) (4990,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diviser les données en ensembles d'entraînement et de test**"
      ],
      "metadata": {
        "id": "F_aic9SLFW1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Diviser les données\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_seq, Y_seq, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "JhBSYAWYFX9T"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ré-afficher les premières lignes\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAjGTXjUKcAF",
        "outputId": "5a3e7b56-4cae-46a5-d222-31b675305329"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Timestamp   Temperature  Vibrations  Pressure   Current  \\\n",
            "0 2024-01-01 00:00:00  8.053077e-16   -0.386230 -0.638846 -0.286213   \n",
            "1 2024-01-01 01:00:00 -1.874606e-01   -0.399682 -0.383149 -0.221113   \n",
            "2 2024-01-01 02:00:00  3.950915e-01   -1.004987 -0.585015 -0.167849   \n",
            "3 2024-01-01 03:00:00  1.008245e+00   -0.345877 -0.100536  0.358868   \n",
            "4 2024-01-01 04:00:00  1.026821e-01    0.000000  0.626181 -0.647222   \n",
            "5 2024-01-01 05:00:00  1.593506e-01   -0.767348 -0.706134 -0.706404   \n",
            "6 2024-01-01 06:00:00  1.206584e+00    0.272880  0.000000  0.530495   \n",
            "7 2024-01-01 07:00:00  8.053077e-16    0.021790 -0.706134 -0.475595   \n",
            "8 2024-01-01 08:00:00 -3.105553e-02   -0.525226 -0.746507 -0.949049   \n",
            "9 2024-01-01 09:00:00  4.528934e-01   -0.260686  0.370484 -0.493349   \n",
            "\n",
            "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
            "0       -1.735686  1.632255    -0.800738           -0.308074          2   \n",
            "1       -1.734649 -0.323866    -0.221101           -0.308074          0   \n",
            "2       -1.733739  0.528210    -1.059419           -0.308074          2   \n",
            "3       -1.732780 -0.705665    -0.362418           -0.308074          0   \n",
            "4       -1.731947 -1.085541    -0.613913           -0.308074          2   \n",
            "5       -1.731463 -0.279627    -1.007922           -0.308074          0   \n",
            "6       -1.731092 -1.402906     0.196860           -0.308074          1   \n",
            "7       -1.730133 -0.994178     0.230392           -0.308074          0   \n",
            "8       -1.729510  0.476278    -0.857025           -0.308074          1   \n",
            "9       -1.728971 -0.586413    -0.405531           -0.308074          0   \n",
            "\n",
            "   Location  State  \n",
            "0         0      0  \n",
            "1         0      0  \n",
            "2         0      0  \n",
            "3         2      0  \n",
            "4         1      0  \n",
            "5         0      0  \n",
            "6         0      0  \n",
            "7         1      0  \n",
            "8         1      0  \n",
            "9         2      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apprentissage, construction du modèle, archivage et gestion des expériences avec WandB**"
      ],
      "metadata": {
        "id": "hP8qNmLDFgm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Développer un modèle LSTM**"
      ],
      "metadata": {
        "id": "pQz6oo6SFh1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "\n",
        "# Construire le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))  # Ajouter une couche Input\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(4, activation='softmax'))  # 4 classes pour l'état de la pompe\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Afficher le résumé du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "KE8TxLuBFkd6",
        "outputId": "473f4473-a01a-4664-aea5-77c99edaa847"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m12,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,404\u001b[0m (48.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,404</span> (48.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,404\u001b[0m (48.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,404</span> (48.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tester plusieurs jeux d'hyperparamètres**"
      ],
      "metadata": {
        "id": "g3JXhR7ZH5Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Définir les hyperparamètres à tester\n",
        "units_list = [30, 50, 100]  # Nombre de neurones dans la couche LSTM\n",
        "optimizer_list = ['adam', 'rmsprop']  # Optimiseurs à tester\n",
        "batch_size_list = [32, 64]  # Taille des lots\n",
        "epochs_list = [10, 20]  # Nombre d'époques\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Boucle pour tester les hyperparamètres\n",
        "for units in units_list:\n",
        "    for optimizer in optimizer_list:\n",
        "        for batch_size in batch_size_list:\n",
        "            for epochs in epochs_list:\n",
        "                print(f\"Test des paramètres: units={units}, optimizer={optimizer}, batch_size={batch_size}, epochs={epochs}\")\n",
        "\n",
        "                # Créer et entraîner le modèle\n",
        "                model = Sequential()\n",
        "                model.add(LSTM(units, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "                model.add(Dense(4, activation='softmax'))\n",
        "                model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "                model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "                # Évaluer le modèle\n",
        "                _, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "                print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "                # Mettre à jour les meilleurs paramètres\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_params = {\n",
        "                        'units': units,\n",
        "                        'optimizer': optimizer,\n",
        "                        'batch_size': batch_size,\n",
        "                        'epochs': epochs\n",
        "                    }\n",
        "\n",
        "# Afficher les meilleurs résultats\n",
        "print(f\"Meilleure précision: {best_accuracy} avec les paramètres {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPJabom4U_wz",
        "outputId": "6e98c69f-c199-40a5-8015-5a312136d529"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test des paramètres: units=30, optimizer=adam, batch_size=32, epochs=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=adam, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=adam, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=adam, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=32, epochs=20\n",
            "Accuracy: 0.854375422000885\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Meilleure précision: 0.8557114005088806 avec les paramètres {'units': 30, 'optimizer': 'adam', 'batch_size': 32, 'epochs': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tester d'autres modèles ML sans considérer la composante temporelle**"
      ],
      "metadata": {
        "id": "JfiGnlEAVHYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplatir les séquences temporelles pour les modèles classiques\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)  # Forme : (n_samples, n_features * window_size)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "QdM_6xu0VIqI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exemple avec Random Forest**"
      ],
      "metadata": {
        "id": "2KqNfDi0VMME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Entraîner un modèle Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_flat, Y_train)\n",
        "\n",
        "# Évaluer le modèle\n",
        "Y_pred_rf = rf_model.predict(X_test_flat)\n",
        "accuracy_rf = accuracy_score(Y_test, Y_pred_rf)\n",
        "precision_rf = precision_score(Y_test, Y_pred_rf, average='weighted')\n",
        "recall_rf = recall_score(Y_test, Y_pred_rf, average='weighted')\n",
        "conf_matrix_rf = confusion_matrix(Y_test, Y_pred_rf)\n",
        "\n",
        "print(\"Random Forest - Accuracy:\", accuracy_rf)\n",
        "print(\"Random Forest - Precision:\", precision_rf)\n",
        "print(\"Random Forest - Recall:\", recall_rf)\n",
        "print(\"Random Forest - Matrice de confusion:\\n\", conf_matrix_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym1WXAXNVPGa",
        "outputId": "0821a061-5794-45c7-831d-c9a1c3882512"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Accuracy: 0.8557114228456913\n",
            "Random Forest - Precision: 0.7322420391885976\n",
            "Random Forest - Recall: 0.8557114228456913\n",
            "Random Forest - Matrice de confusion:\n",
            " [[1281    0    0    0]\n",
            " [  63    0    0    0]\n",
            " [  67    0    0    0]\n",
            " [  86    0    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exemple avec SVM**"
      ],
      "metadata": {
        "id": "7ZcJ3qagVRQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Entraîner un modèle SVM\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train_flat, Y_train)\n",
        "\n",
        "# Évaluer le modèle\n",
        "Y_pred_svm = svm_model.predict(X_test_flat)\n",
        "accuracy_svm = accuracy_score(Y_test, Y_pred_svm)\n",
        "precision_svm = precision_score(Y_test, Y_pred_svm, average='weighted')\n",
        "recall_svm = recall_score(Y_test, Y_pred_svm, average='weighted')\n",
        "conf_matrix_svm = confusion_matrix(Y_test, Y_pred_svm)\n",
        "\n",
        "print(\"SVM - Accuracy:\", accuracy_svm)\n",
        "print(\"SVM - Precision:\", precision_svm)\n",
        "print(\"SVM - Recall:\", recall_svm)\n",
        "print(\"SVM - Matrice de confusion:\\n\", conf_matrix_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndLWW1caVUL4",
        "outputId": "30b6e61c-04f6-4f5b-8260-9c68403405cf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Accuracy: 0.8557114228456913\n",
            "SVM - Precision: 0.7322420391885976\n",
            "SVM - Recall: 0.8557114228456913\n",
            "SVM - Matrice de confusion:\n",
            " [[1281    0    0    0]\n",
            " [  63    0    0    0]\n",
            " [  67    0    0    0]\n",
            " [  86    0    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tracer l'apprentissage avec Weights and Biases**"
      ],
      "metadata": {
        "id": "-VrHDBazK3VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback # Import WandbCallback from the correct submodule\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "34XL2v6JMCZV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback # Import WandbCallback from the correct submodule\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Initialiser Weights and Biases\n",
        "wandb.init(project=\"maintenance-predictive\", config={\n",
        "    \"units\": 50,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 20,\n",
        "    \"window_size\": 10\n",
        "})\n",
        "\n",
        "# Construire le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(wandb.config.units, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(optimizer=wandb.config.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle avec WandB\n",
        "# Disable graph saving explicitly using save_graph=False\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=wandb.config.epochs,\n",
        "    batch_size=wandb.config.batch_size,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[WandbCallback(save_model=False, save_graph=False)]\n",
        ")\n",
        "\n",
        "\n",
        "# Enregistrer le modèle\n",
        "model.save(\"lstm_model.h5\")\n",
        "wandb.save(\"lstm_model.h5\") # wandb.save is used to upload the model to wandb\n",
        "\n",
        "# Terminer la session WandB\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dda1wAVilNo8",
        "outputId": "68e54168-3882-44a6-d9c7-b4dbfe46fed2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.7430 - loss: 0.8636 - val_accuracy: 0.8557 - val_loss: 0.5816\n",
            "Epoch 2/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8471 - loss: 0.5977 - val_accuracy: 0.8557 - val_loss: 0.5798\n",
            "Epoch 3/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8514 - loss: 0.5813 - val_accuracy: 0.8557 - val_loss: 0.5802\n",
            "Epoch 4/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8478 - loss: 0.5900 - val_accuracy: 0.8557 - val_loss: 0.5783\n",
            "Epoch 5/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8538 - loss: 0.5707 - val_accuracy: 0.8557 - val_loss: 0.5797\n",
            "Epoch 6/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8374 - loss: 0.6094 - val_accuracy: 0.8557 - val_loss: 0.5780\n",
            "Epoch 7/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8321 - loss: 0.6280 - val_accuracy: 0.8557 - val_loss: 0.5845\n",
            "Epoch 8/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.6006 - val_accuracy: 0.8557 - val_loss: 0.5861\n",
            "Epoch 9/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8496 - loss: 0.5802 - val_accuracy: 0.8557 - val_loss: 0.5892\n",
            "Epoch 10/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8471 - loss: 0.5793 - val_accuracy: 0.8557 - val_loss: 0.5866\n",
            "Epoch 11/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8522 - loss: 0.5696 - val_accuracy: 0.8557 - val_loss: 0.5869\n",
            "Epoch 12/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8573 - loss: 0.5472 - val_accuracy: 0.8557 - val_loss: 0.5866\n",
            "Epoch 13/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8381 - loss: 0.5951 - val_accuracy: 0.8557 - val_loss: 0.5857\n",
            "Epoch 14/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8507 - loss: 0.5646 - val_accuracy: 0.8557 - val_loss: 0.5901\n",
            "Epoch 15/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8463 - loss: 0.5651 - val_accuracy: 0.8557 - val_loss: 0.5933\n",
            "Epoch 16/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8389 - loss: 0.5858 - val_accuracy: 0.8557 - val_loss: 0.5942\n",
            "Epoch 17/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8403 - loss: 0.5784 - val_accuracy: 0.8557 - val_loss: 0.5950\n",
            "Epoch 18/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8422 - loss: 0.5685 - val_accuracy: 0.8557 - val_loss: 0.6038\n",
            "Epoch 19/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8443 - loss: 0.5566 - val_accuracy: 0.8557 - val_loss: 0.5975\n",
            "Epoch 20/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8475 - loss: 0.5495 - val_accuracy: 0.8557 - val_loss: 0.6107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▅███████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▇▆▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▂▁▁▁▁▁▂▃▃▃▃▃▃▄▄▄▅▇▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.84712</td></tr><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.57799</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.54869</td></tr><tr><td>val_accuracy</td><td>0.85571</td></tr><tr><td>val_loss</td><td>0.61072</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devoted-violet-14</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/z2ytnb7y' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/z2ytnb7y</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_115911-z2ytnb7y/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Archiver les modèles testés dans Weights and Biases**"
      ],
      "metadata": {
        "id": "eYJfy-tvSk48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback # Import WandbCallback from the correct submodule\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Initialiser Weights and Biases\n",
        "wandb.init(project=\"maintenance-predictive\", config={\n",
        "    \"units\": 50,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 20,\n",
        "    \"window_size\": 10\n",
        "})\n",
        "\n",
        "# Construire le modèle LSTM complexe\n",
        "model = Sequential()\n",
        "\n",
        "# Première couche LSTM avec retour des séquences pour empiler une deuxième couche LSTM\n",
        "model.add(LSTM(\n",
        "    wandb.config.units,  # Nombre de neurones dans la couche LSTM\n",
        "    input_shape=(X_train.shape[1], X_train.shape[2]),  # Forme d'entrée\n",
        "    return_sequences=True  # Retourne une séquence pour la couche suivante\n",
        "))\n",
        "\n",
        "# Ajouter une couche Dropout pour la régularisation\n",
        "model.add(Dropout(0.2))  # Désactive 20 % des neurones pendant l'entraînement\n",
        "\n",
        "# Deuxième couche LSTM\n",
        "model.add(LSTM(\n",
        "    wandb.config.units // 2,  # Moitié de neurones par rapport à la première couche\n",
        "    return_sequences=False  # Ne retourne pas de séquence (dernière couche LSTM)\n",
        "))\n",
        "\n",
        "# Ajouter une couche Dense intermédiaire\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurones avec activation ReLU\n",
        "\n",
        "# Ajouter une autre couche Dropout\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Couche de sortie\n",
        "model.add(Dense(4, activation='softmax'))  # 4 classes pour l'état de la pompe\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(\n",
        "    optimizer=wandb.config.optimizer,  # Optimiseur configuré dans WandB\n",
        "    loss='sparse_categorical_crossentropy',  # Fonction de perte\n",
        "    metrics=['accuracy']  # Métrique à surveiller\n",
        ")\n",
        "\n",
        "# Afficher le résumé du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-5q4u410gTJX",
        "outputId": "09bd44e7-4039-4a77-f08d-7bcbc5ddbf8e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250321_121035-9wajtkgg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/9wajtkgg' target=\"_blank\">zesty-sound-15</a></strong> to <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/9wajtkgg' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/9wajtkgg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │          \u001b[38;5;34m12,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m7,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m260\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,724\u001b[0m (84.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,724</span> (84.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,724\u001b[0m (84.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,724</span> (84.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle avec WandB\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=wandb.config.epochs,\n",
        "    batch_size=wandb.config.batch_size,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[WandbCallback(save_model=False, save_graph=False)]  # Disable graph saving\n",
        ")\n",
        "\n",
        "# Enregistrer le modèle\n",
        "model.save(\"lstm_complex_model.h5\")\n",
        "wandb.save(\"lstm_complex_model.h5\")\n",
        "\n",
        "# Terminer la session WandB\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NvpLZW5jjqrK",
        "outputId": "eab3420c-48af-451c-8d8c-0adfe77c1bb8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8446 - loss: 0.8190 - val_accuracy: 0.8557 - val_loss: 0.5762\n",
            "Epoch 2/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8443 - loss: 0.6176 - val_accuracy: 0.8557 - val_loss: 0.5909\n",
            "Epoch 3/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8570 - loss: 0.5717 - val_accuracy: 0.8557 - val_loss: 0.5730\n",
            "Epoch 4/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8563 - loss: 0.5778 - val_accuracy: 0.8557 - val_loss: 0.5786\n",
            "Epoch 5/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8466 - loss: 0.6047 - val_accuracy: 0.8557 - val_loss: 0.5748\n",
            "Epoch 6/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8479 - loss: 0.5972 - val_accuracy: 0.8557 - val_loss: 0.5746\n",
            "Epoch 7/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8474 - loss: 0.5996 - val_accuracy: 0.8557 - val_loss: 0.5774\n",
            "Epoch 8/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8433 - loss: 0.6117 - val_accuracy: 0.8557 - val_loss: 0.5787\n",
            "Epoch 9/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8362 - loss: 0.6314 - val_accuracy: 0.8557 - val_loss: 0.5787\n",
            "Epoch 10/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8496 - loss: 0.5882 - val_accuracy: 0.8557 - val_loss: 0.5773\n",
            "Epoch 11/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8554 - loss: 0.5703 - val_accuracy: 0.8557 - val_loss: 0.5786\n",
            "Epoch 12/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8511 - loss: 0.5863 - val_accuracy: 0.8557 - val_loss: 0.5783\n",
            "Epoch 13/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8423 - loss: 0.6028 - val_accuracy: 0.8557 - val_loss: 0.5776\n",
            "Epoch 14/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8548 - loss: 0.5704 - val_accuracy: 0.8557 - val_loss: 0.5811\n",
            "Epoch 15/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8440 - loss: 0.5954 - val_accuracy: 0.8557 - val_loss: 0.5880\n",
            "Epoch 16/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8568 - loss: 0.5468 - val_accuracy: 0.8557 - val_loss: 0.5897\n",
            "Epoch 17/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8590 - loss: 0.5505 - val_accuracy: 0.8557 - val_loss: 0.5880\n",
            "Epoch 18/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8495 - loss: 0.5627 - val_accuracy: 0.8557 - val_loss: 0.5919\n",
            "Epoch 19/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8478 - loss: 0.5683 - val_accuracy: 0.8557 - val_loss: 0.5940\n",
            "Epoch 20/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8469 - loss: 0.5637 - val_accuracy: 0.8557 - val_loss: 0.5919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▇▁▃▂▂▂▃▃▂▃▃▃▄▆▇▆▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.84741</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.57296</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.56743</td></tr><tr><td>val_accuracy</td><td>0.85571</td></tr><tr><td>val_loss</td><td>0.59188</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">zesty-sound-15</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/9wajtkgg' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/9wajtkgg</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_121035-9wajtkgg/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "Dyus7FdVTUDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluer les modèles**"
      ],
      "metadata": {
        "id": "AjWG4RgYTVfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "Y_pred = model.predict(X_test)\n",
        "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# Calculer les métriques\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred_classes)\n",
        "accuracy = accuracy_score(Y_test, Y_pred_classes)\n",
        "precision = precision_score(Y_test, Y_pred_classes, average='weighted')\n",
        "recall = recall_score(Y_test, Y_pred_classes, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8CDJnFTYAu",
        "outputId": "cfd4d8c4-c189-47a5-80e9-d99cb4d8f122"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Confusion Matrix:\n",
            " [[1281    0    0    0]\n",
            " [  63    0    0    0]\n",
            " [  67    0    0    0]\n",
            " [  86    0    0    0]]\n",
            "Accuracy: 0.8557114228456913\n",
            "Precision: 0.7322420391885976\n",
            "Recall: 0.8557114228456913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Modèle LSTM plus complexe\n",
        "model = Sequential()\n",
        "\n",
        "# Première couche LSTM avec retour des séquences pour empiler une deuxième couche LSTM\n",
        "model.add(LSTM(\n",
        "    units=64,  # Nombre de neurones dans la couche LSTM\n",
        "    input_shape=(X_train.shape[1], X_train.shape[2]),  # Forme d'entrée\n",
        "    return_sequences=True  # Retourne une séquence pour la couche suivante\n",
        "))\n",
        "\n",
        "# Ajouter une couche Dropout pour la régularisation\n",
        "model.add(Dropout(0.2))  # Désactive 20 % des neurones pendant l'entraînement\n",
        "\n",
        "# Deuxième couche LSTM\n",
        "model.add(LSTM(\n",
        "    units=32,  # Moitié de neurones par rapport à la première couche\n",
        "    return_sequences=False  # Ne retourne pas de séquence (dernière couche LSTM)\n",
        "))\n",
        "\n",
        "# Ajouter une couche Dense intermédiaire\n",
        "model.add(Dense(64, activation='relu'))  # 64 neurones avec activation ReLU\n",
        "\n",
        "# Ajouter une autre couche Dropout\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Couche de sortie\n",
        "model.add(Dense(4, activation='softmax'))  # 4 classes pour l'état de la pompe\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(\n",
        "    optimizer='adam',  # Optimiseur\n",
        "    loss='sparse_categorical_crossentropy',  # Fonction de perte\n",
        "    metrics=['accuracy']  # Métrique à surveiller\n",
        ")\n",
        "\n",
        "# Afficher le résumé du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "YHZKNqlsqy_G",
        "outputId": "bbc0c25e-0c98-4e1b-e15e-79e075333f8b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_18\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_18\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m19,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m260\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,988\u001b[0m (132.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,988</span> (132.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,988\u001b[0m (132.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,988</span> (132.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback # Import WandbCallback from the correct submodule\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Initialiser Weights and Biases\n",
        "wandb.init(project=\"maintenance-predictive\", config={\n",
        "    \"units\": 50,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 20,\n",
        "    \"window_size\": 10\n",
        "})\n",
        "\n",
        "\n",
        "# Entraîner le modèle avec WandB\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    # Access the config values after wandb.init()\n",
        "    epochs=wandb.config.epochs,\n",
        "    batch_size=wandb.config.batch_size,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[WandbCallback(save_model=False, save_graph=False)]  # Disable graph saving\n",
        ")\n",
        "\n",
        "# Enregistrer le modèle\n",
        "model.save(\"lstm_complex_model.h5\")\n",
        "wandb.save(\"lstm_complex_model.h5\")\n",
        "\n",
        "# Terminer la session WandB\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-UR9N8e9q6IN",
        "outputId": "02c0da29-e06c-4104-9a17-8c8e4581760d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250321_122900-51l0t17d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/51l0t17d' target=\"_blank\">dulcet-microwave-18</a></strong> to <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/51l0t17d' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/51l0t17d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8141 - loss: 0.8301 - val_accuracy: 0.8557 - val_loss: 0.5824\n",
            "Epoch 2/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8571 - loss: 0.5741 - val_accuracy: 0.8557 - val_loss: 0.5742\n",
            "Epoch 3/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8461 - loss: 0.6085 - val_accuracy: 0.8557 - val_loss: 0.5724\n",
            "Epoch 4/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8554 - loss: 0.5811 - val_accuracy: 0.8557 - val_loss: 0.5743\n",
            "Epoch 5/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8481 - loss: 0.6021 - val_accuracy: 0.8557 - val_loss: 0.5749\n",
            "Epoch 6/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8399 - loss: 0.6267 - val_accuracy: 0.8557 - val_loss: 0.5765\n",
            "Epoch 7/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8505 - loss: 0.5942 - val_accuracy: 0.8557 - val_loss: 0.5772\n",
            "Epoch 8/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8460 - loss: 0.6044 - val_accuracy: 0.8557 - val_loss: 0.5770\n",
            "Epoch 9/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8456 - loss: 0.6064 - val_accuracy: 0.8557 - val_loss: 0.5770\n",
            "Epoch 10/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8508 - loss: 0.5894 - val_accuracy: 0.8557 - val_loss: 0.5746\n",
            "Epoch 11/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8423 - loss: 0.6098 - val_accuracy: 0.8557 - val_loss: 0.5801\n",
            "Epoch 12/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8489 - loss: 0.5841 - val_accuracy: 0.8557 - val_loss: 0.5770\n",
            "Epoch 13/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8523 - loss: 0.5713 - val_accuracy: 0.8557 - val_loss: 0.5769\n",
            "Epoch 14/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8450 - loss: 0.5930 - val_accuracy: 0.8557 - val_loss: 0.5855\n",
            "Epoch 15/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8531 - loss: 0.5693 - val_accuracy: 0.8557 - val_loss: 0.5967\n",
            "Epoch 16/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8431 - loss: 0.5825 - val_accuracy: 0.8557 - val_loss: 0.5884\n",
            "Epoch 17/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8422 - loss: 0.5808 - val_accuracy: 0.8557 - val_loss: 0.5930\n",
            "Epoch 18/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8499 - loss: 0.5542 - val_accuracy: 0.8557 - val_loss: 0.5937\n",
            "Epoch 19/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8430 - loss: 0.5667 - val_accuracy: 0.8557 - val_loss: 0.5969\n",
            "Epoch 20/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8489 - loss: 0.5429 - val_accuracy: 0.8557 - val_loss: 0.6172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁███████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▃▁▁▁▁▂▂▂▂▁▂▂▂▃▅▄▄▄▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.84741</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.57244</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.55186</td></tr><tr><td>val_accuracy</td><td>0.85571</td></tr><tr><td>val_loss</td><td>0.61719</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dulcet-microwave-18</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/51l0t17d' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/51l0t17d</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_122900-51l0t17d/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Archivage des modèles**"
      ],
      "metadata": {
        "id": "JSmu33xoXE3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder le modèle Random Forest\n",
        "import joblib\n",
        "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
        "\n",
        "# Initialiser une nouvelle session WandB pour l'archivage\n",
        "wandb.init(project=\"maintenance-predictive\", job_type=\"model_archiving\")\n",
        "\n",
        "# Archiver dans WandB\n",
        "wandb.save('random_forest_model.pkl')\n",
        "\n",
        "# Terminer la session WandB d'archivage\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "PfYYM1p7XF3D",
        "outputId": "e72fed93-5941-4b2e-b750-722c7c61de90"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250321_121830-kd5vloxp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/kd5vloxp' target=\"_blank\">olive-waterfall-16</a></strong> to <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/kd5vloxp' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/kd5vloxp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">olive-waterfall-16</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/kd5vloxp' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/kd5vloxp</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_121830-kd5vloxp/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intégration applicative**"
      ],
      "metadata": {
        "id": "c-reJA7PTjQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intégrer le modèle dans une API Flask**"
      ],
      "metadata": {
        "id": "MB0iFGgFTkhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Charger le modèle\n",
        "model = tf.keras.models.load_model('lstm_model.h5')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Récupérer les données de la requête POST\n",
        "    data = request.json.get('data')\n",
        "\n",
        "    # Convertir les données en un tableau numpy\n",
        "    data = np.array(data)\n",
        "\n",
        "    # Vérifier que les données ont la bonne forme (10 pas de temps, 10 caractéristiques)\n",
        "    if data.shape != (10, 10):\n",
        "        return jsonify({\"error\": \"Les données doivent avoir la forme (10, 10)\"}), 400\n",
        "\n",
        "    # Redimensionner les données pour correspondre à l'entrée du modèle (1, 10, 10)\n",
        "    data = data.reshape(1, 10, 10)\n",
        "\n",
        "    # Faire la prédiction\n",
        "    prediction = model.predict(data)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "\n",
        "    # Retourner la prédiction\n",
        "    return jsonify({\"predicted_state\": int(predicted_class[0])})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8muZgbmjTnBF",
        "outputId": "b9f45590-0bf2-446d-c167-540c102fcc8b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}