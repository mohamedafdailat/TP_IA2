{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNqsD1CPRYeNOd8qWz1foe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedafdailat/TP_IA2/blob/main/TP_IA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyse des données**"
      ],
      "metadata": {
        "id": "eGpLJVAqBxdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Charger les données et afficher les premières lignes**"
      ],
      "metadata": {
        "id": "1PvGdYzHCAlK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlDWXjheBsnz",
        "outputId": "d2d04e61-8cc3-4903-9958-98841db97827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
            "0  2024-01-01 00:00:00          NaN        2.58      3.16    11.86   \n",
            "1  2024-01-01 01:00:00        55.60        2.55      3.35    11.97   \n",
            "2  2024-01-01 02:00:00        60.74        1.20      3.20    12.06   \n",
            "3  2024-01-01 03:00:00        66.15        2.67      3.56    12.95   \n",
            "4  2024-01-01 04:00:00        58.16         NaN      4.10    11.25   \n",
            "\n",
            "   Operating_Time  Humidity  Noise_Level  Energy_Consumption   Pump_Type  \\\n",
            "0            0.56     67.93        65.62                0.01      Piston   \n",
            "1            2.04     47.59        70.46                0.01  Centrifuge   \n",
            "2            3.34     56.45        63.46                0.01      Piston   \n",
            "3            4.71     43.62        69.28                0.01  Centrifuge   \n",
            "4            5.90     39.67        67.18                0.01      Piston   \n",
            "\n",
            "  Location  State  \n",
            "0   Zone A      0  \n",
            "1   Zone A      0  \n",
            "2   Zone A      0  \n",
            "3   Zone C      0  \n",
            "4   Zone B      0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le dataset\n",
        "df = pd.read_csv('maintenance_predictive.csv')\n",
        "\n",
        "# Afficher les premières lignes\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identifier les colonnes, types de données et valeurs manquantes**"
      ],
      "metadata": {
        "id": "_7nNY9KtBv2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les informations sur les colonnes et les types de données\n",
        "print(df.info())\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dig4LoFCnl4",
        "outputId": "0d63d44d-bece-4850-811d-ffd1fbf30cd6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 12 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Timestamp           5000 non-null   object \n",
            " 1   Temperature         4750 non-null   float64\n",
            " 2   Vibrations          4750 non-null   float64\n",
            " 3   Pressure            4750 non-null   float64\n",
            " 4   Current             4750 non-null   float64\n",
            " 5   Operating_Time      5000 non-null   float64\n",
            " 6   Humidity            4750 non-null   float64\n",
            " 7   Noise_Level         4750 non-null   float64\n",
            " 8   Energy_Consumption  4750 non-null   float64\n",
            " 9   Pump_Type           5000 non-null   object \n",
            " 10  Location            5000 non-null   object \n",
            " 11  State               5000 non-null   int64  \n",
            "dtypes: float64(8), int64(1), object(3)\n",
            "memory usage: 468.9+ KB\n",
            "None\n",
            "Timestamp               0\n",
            "Temperature           250\n",
            "Vibrations            250\n",
            "Pressure              250\n",
            "Current               250\n",
            "Operating_Time          0\n",
            "Humidity              250\n",
            "Noise_Level           250\n",
            "Energy_Consumption    250\n",
            "Pump_Type               0\n",
            "Location                0\n",
            "State                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculer des statistiques de base**"
      ],
      "metadata": {
        "id": "cyGqS1ZICuEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer des statistiques de base\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDxTxhTdCxFt",
        "outputId": "5f58a9b4-75ed-4d28-cd86-715e40ad9e6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Temperature   Vibrations     Pressure      Current  Operating_Time  \\\n",
            "count  4750.000000  4750.000000  4750.000000  4750.000000     5000.000000   \n",
            "mean     57.254011     3.441402     3.634705    12.343617     2479.450176   \n",
            "std       9.053411     2.288461     0.762451     1.733788     1428.333659   \n",
            "min      35.610000    -0.920000     1.810000     8.140000        0.560000   \n",
            "25%      51.550000     2.350000     3.190000    11.380000     1244.915000   \n",
            "50%      55.855000     3.040000     3.530000    12.070000     2483.700000   \n",
            "75%      60.957500     3.800000     3.900000    12.840000     3714.692500   \n",
            "max      89.970000    14.890000     7.000000    19.990000     4956.740000   \n",
            "\n",
            "          Humidity  Noise_Level  Energy_Consumption        State  \n",
            "count  4750.000000  4750.000000         4750.000000  5000.000000  \n",
            "mean     50.957598    72.306211            0.011158     0.296800  \n",
            "std      10.669382     8.567884            0.003857     0.775648  \n",
            "min      15.050000    47.670000            0.010000     0.000000  \n",
            "25%      43.532500    66.940000            0.010000     0.000000  \n",
            "50%      50.630000    70.670000            0.010000     0.000000  \n",
            "75%      57.787500    74.940000            0.010000     0.000000  \n",
            "max      86.920000    99.950000            0.030000     3.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pré-traitement des données**"
      ],
      "metadata": {
        "id": "azglCVGUDBYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder les variables catégoriques**"
      ],
      "metadata": {
        "id": "nfjDXV3DDCp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoder les variables catégoriques\n",
        "label_encoder = LabelEncoder()\n",
        "df['Pump_Type'] = label_encoder.fit_transform(df['Pump_Type'])\n",
        "df['Location'] = label_encoder.fit_transform(df['Location'])"
      ],
      "metadata": {
        "id": "QlaG08pWDFnD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0AvzcIMHJp8",
        "outputId": "33d8dac2-f8ab-4767-d430-3d2ebc3fe401"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gérer les données manquantes**"
      ],
      "metadata": {
        "id": "RYtZsfUGDgbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoder les variables catégoriques\n",
        "label_encoder = LabelEncoder()\n",
        "df['Pump_Type'] = label_encoder.fit_transform(df['Pump_Type'])\n",
        "df['Location'] = label_encoder.fit_transform(df['Location'])\n",
        "\n",
        "# Remplacer les valeurs manquantes par la moyenne des colonnes numériques uniquement\n",
        "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQHQ09ccDi0q",
        "outputId": "cc2df526-aed4-490f-ef73-2c0c72cb2d0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Timestamp  Temperature  Vibrations  Pressure  Current  \\\n",
            "0  2024-01-01 00:00:00    57.254011    2.580000      3.16    11.86   \n",
            "1  2024-01-01 01:00:00    55.600000    2.550000      3.35    11.97   \n",
            "2  2024-01-01 02:00:00    60.740000    1.200000      3.20    12.06   \n",
            "3  2024-01-01 03:00:00    66.150000    2.670000      3.56    12.95   \n",
            "4  2024-01-01 04:00:00    58.160000    3.441402      4.10    11.25   \n",
            "\n",
            "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
            "0            0.56     67.93        65.62                0.01          2   \n",
            "1            2.04     47.59        70.46                0.01          0   \n",
            "2            3.34     56.45        63.46                0.01          2   \n",
            "3            4.71     43.62        69.28                0.01          0   \n",
            "4            5.90     39.67        67.18                0.01          2   \n",
            "\n",
            "   Location  State  \n",
            "0         0      0  \n",
            "1         0      0  \n",
            "2         0      0  \n",
            "3         2      0  \n",
            "4         1      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convertir la colonne Timestamp en datetime**"
      ],
      "metadata": {
        "id": "KzHmJDFfEizg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la colonne Timestamp en datetime\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "# Trier les données par Timestamp\n",
        "df.sort_values('Timestamp', inplace=True)"
      ],
      "metadata": {
        "id": "BgohQdatEjyF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normaliser ou standardiser les variables numériques**"
      ],
      "metadata": {
        "id": "XQMD-JZPEwOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normaliser les variables numériques\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['Temperature', 'Vibrations', 'Pressure', 'Current', 'Operating_Time', 'Humidity', 'Noise_Level', 'Energy_Consumption']\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
      ],
      "metadata": {
        "id": "l1T10PL3Exgb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Créer les vecteurs X et Y**"
      ],
      "metadata": {
        "id": "PZfXfQczE45c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer les vecteurs X et Y\n",
        "X = df.drop(columns=['State', 'Timestamp'])\n",
        "Y = df['State']"
      ],
      "metadata": {
        "id": "YIMt8agxE6G8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Créer des séquences temporelles**"
      ],
      "metadata": {
        "id": "g2_-NTlNFERo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(data, target, window_size):\n",
        "    X_seq, Y_seq = [], []\n",
        "    for i in range(len(data) - window_size):\n",
        "        X_seq.append(data[i:i+window_size])\n",
        "        Y_seq.append(target[i+window_size])\n",
        "    return np.array(X_seq), np.array(Y_seq)\n",
        "\n",
        "window_size = 10\n",
        "X_seq, Y_seq = create_sequences(X.values, Y.values, window_size)\n",
        "\n",
        "# Vérifier la taille des séquences\n",
        "print(X_seq.shape, Y_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrloMdHnFFdO",
        "outputId": "03c099ca-4fc6-4017-fd48-1b2a044d32ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4990, 10, 10) (4990,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diviser les données en ensembles d'entraînement et de test**"
      ],
      "metadata": {
        "id": "F_aic9SLFW1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Diviser les données\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_seq, Y_seq, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "JhBSYAWYFX9T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ré-afficher les premières lignes\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAjGTXjUKcAF",
        "outputId": "e36226e6-e8dd-4f81-bd67-34fe7b5464a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Timestamp   Temperature  Vibrations  Pressure   Current  \\\n",
            "0 2024-01-01 00:00:00  8.053077e-16   -0.386230 -0.638846 -0.286213   \n",
            "1 2024-01-01 01:00:00 -1.874606e-01   -0.399682 -0.383149 -0.221113   \n",
            "2 2024-01-01 02:00:00  3.950915e-01   -1.004987 -0.585015 -0.167849   \n",
            "3 2024-01-01 03:00:00  1.008245e+00   -0.345877 -0.100536  0.358868   \n",
            "4 2024-01-01 04:00:00  1.026821e-01    0.000000  0.626181 -0.647222   \n",
            "5 2024-01-01 05:00:00  1.593506e-01   -0.767348 -0.706134 -0.706404   \n",
            "6 2024-01-01 06:00:00  1.206584e+00    0.272880  0.000000  0.530495   \n",
            "7 2024-01-01 07:00:00  8.053077e-16    0.021790 -0.706134 -0.475595   \n",
            "8 2024-01-01 08:00:00 -3.105553e-02   -0.525226 -0.746507 -0.949049   \n",
            "9 2024-01-01 09:00:00  4.528934e-01   -0.260686  0.370484 -0.493349   \n",
            "\n",
            "   Operating_Time  Humidity  Noise_Level  Energy_Consumption  Pump_Type  \\\n",
            "0       -1.735686  1.632255    -0.800738           -0.308074          2   \n",
            "1       -1.734649 -0.323866    -0.221101           -0.308074          0   \n",
            "2       -1.733739  0.528210    -1.059419           -0.308074          2   \n",
            "3       -1.732780 -0.705665    -0.362418           -0.308074          0   \n",
            "4       -1.731947 -1.085541    -0.613913           -0.308074          2   \n",
            "5       -1.731463 -0.279627    -1.007922           -0.308074          0   \n",
            "6       -1.731092 -1.402906     0.196860           -0.308074          1   \n",
            "7       -1.730133 -0.994178     0.230392           -0.308074          0   \n",
            "8       -1.729510  0.476278    -0.857025           -0.308074          1   \n",
            "9       -1.728971 -0.586413    -0.405531           -0.308074          0   \n",
            "\n",
            "   Location  State  \n",
            "0         0      0  \n",
            "1         0      0  \n",
            "2         0      0  \n",
            "3         2      0  \n",
            "4         1      0  \n",
            "5         0      0  \n",
            "6         0      0  \n",
            "7         1      0  \n",
            "8         1      0  \n",
            "9         2      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apprentissage, construction du modèle, archivage et gestion des expériences avec WandB**"
      ],
      "metadata": {
        "id": "hP8qNmLDFgm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Développer un modèle LSTM**"
      ],
      "metadata": {
        "id": "pQz6oo6SFh1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "\n",
        "# Construire le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))  # Ajouter une couche Input\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(4, activation='softmax'))  # 4 classes pour l'état de la pompe\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Afficher le résumé du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "KE8TxLuBFkd6",
        "outputId": "c9bb91fe-8d27-4873-9d31-a9194eba747e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m12,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m204\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,404\u001b[0m (48.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,404</span> (48.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,404\u001b[0m (48.45 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,404</span> (48.45 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tester plusieurs jeux d'hyperparamètres**"
      ],
      "metadata": {
        "id": "g3JXhR7ZH5Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Définir les hyperparamètres à tester\n",
        "units_list = [30, 50, 100]  # Nombre de neurones dans la couche LSTM\n",
        "optimizer_list = ['adam', 'rmsprop']  # Optimiseurs à tester\n",
        "batch_size_list = [32, 64]  # Taille des lots\n",
        "epochs_list = [10, 20]  # Nombre d'époques\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Boucle pour tester les hyperparamètres\n",
        "for units in units_list:\n",
        "    for optimizer in optimizer_list:\n",
        "        for batch_size in batch_size_list:\n",
        "            for epochs in epochs_list:\n",
        "                print(f\"Test des paramètres: units={units}, optimizer={optimizer}, batch_size={batch_size}, epochs={epochs}\")\n",
        "\n",
        "                # Créer et entraîner le modèle\n",
        "                model = Sequential()\n",
        "                model.add(LSTM(units, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "                model.add(Dense(4, activation='softmax'))\n",
        "                model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "                model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "                # Évaluer le modèle\n",
        "                _, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "                print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "                # Mettre à jour les meilleurs paramètres\n",
        "                if accuracy > best_accuracy:\n",
        "                    best_accuracy = accuracy\n",
        "                    best_params = {\n",
        "                        'units': units,\n",
        "                        'optimizer': optimizer,\n",
        "                        'batch_size': batch_size,\n",
        "                        'epochs': epochs\n",
        "                    }\n",
        "\n",
        "# Afficher les meilleurs résultats\n",
        "print(f\"Meilleure précision: {best_accuracy} avec les paramètres {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPJabom4U_wz",
        "outputId": "6e98c69f-c199-40a5-8015-5a312136d529"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test des paramètres: units=30, optimizer=adam, batch_size=32, epochs=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=adam, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=adam, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=adam, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=30, optimizer=rmsprop, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=adam, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=50, optimizer=rmsprop, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=32, epochs=20\n",
            "Accuracy: 0.854375422000885\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=adam, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=32, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=32, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=64, epochs=10\n",
            "Accuracy: 0.8557114005088806\n",
            "Test des paramètres: units=100, optimizer=rmsprop, batch_size=64, epochs=20\n",
            "Accuracy: 0.8557114005088806\n",
            "Meilleure précision: 0.8557114005088806 avec les paramètres {'units': 30, 'optimizer': 'adam', 'batch_size': 32, 'epochs': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tester d'autres modèles ML sans considérer la composante temporelle**"
      ],
      "metadata": {
        "id": "JfiGnlEAVHYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplatir les séquences temporelles pour les modèles classiques\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)  # Forme : (n_samples, n_features * window_size)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "QdM_6xu0VIqI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exemple avec Random Forest**"
      ],
      "metadata": {
        "id": "2KqNfDi0VMME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Entraîner un modèle Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_flat, Y_train)\n",
        "\n",
        "# Évaluer le modèle\n",
        "Y_pred_rf = rf_model.predict(X_test_flat)\n",
        "accuracy_rf = accuracy_score(Y_test, Y_pred_rf)\n",
        "precision_rf = precision_score(Y_test, Y_pred_rf, average='weighted')\n",
        "recall_rf = recall_score(Y_test, Y_pred_rf, average='weighted')\n",
        "conf_matrix_rf = confusion_matrix(Y_test, Y_pred_rf)\n",
        "\n",
        "print(\"Random Forest - Accuracy:\", accuracy_rf)\n",
        "print(\"Random Forest - Precision:\", precision_rf)\n",
        "print(\"Random Forest - Recall:\", recall_rf)\n",
        "print(\"Random Forest - Matrice de confusion:\\n\", conf_matrix_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym1WXAXNVPGa",
        "outputId": "ca08b04d-0271-43a9-f65c-6d5841a7b3b3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Accuracy: 0.8557114228456913\n",
            "Random Forest - Precision: 0.7322420391885976\n",
            "Random Forest - Recall: 0.8557114228456913\n",
            "Random Forest - Matrice de confusion:\n",
            " [[1281    0    0    0]\n",
            " [  63    0    0    0]\n",
            " [  67    0    0    0]\n",
            " [  86    0    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exemple avec SVM**"
      ],
      "metadata": {
        "id": "7ZcJ3qagVRQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Entraîner un modèle SVM\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train_flat, Y_train)\n",
        "\n",
        "# Évaluer le modèle\n",
        "Y_pred_svm = svm_model.predict(X_test_flat)\n",
        "accuracy_svm = accuracy_score(Y_test, Y_pred_svm)\n",
        "precision_svm = precision_score(Y_test, Y_pred_svm, average='weighted')\n",
        "recall_svm = recall_score(Y_test, Y_pred_svm, average='weighted')\n",
        "conf_matrix_svm = confusion_matrix(Y_test, Y_pred_svm)\n",
        "\n",
        "print(\"SVM - Accuracy:\", accuracy_svm)\n",
        "print(\"SVM - Precision:\", precision_svm)\n",
        "print(\"SVM - Recall:\", recall_svm)\n",
        "print(\"SVM - Matrice de confusion:\\n\", conf_matrix_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndLWW1caVUL4",
        "outputId": "0ba41570-94ae-4d96-ced4-93f18ca132a1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - Accuracy: 0.8557114228456913\n",
            "SVM - Precision: 0.7322420391885976\n",
            "SVM - Recall: 0.8557114228456913\n",
            "SVM - Matrice de confusion:\n",
            " [[1281    0    0    0]\n",
            " [  63    0    0    0]\n",
            " [  67    0    0    0]\n",
            " [  86    0    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tracer l'apprentissage avec Weights and Biases**"
      ],
      "metadata": {
        "id": "-VrHDBazK3VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback # Import WandbCallback from the correct submodule\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "34XL2v6JMCZV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiser Weights and Biases\n",
        "wandb.init(project=\"maintenance-predictive\", config={\n",
        "    \"units\": 50,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 20\n",
        "})\n",
        "\n",
        "# Construire le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle avec WandB\n",
        "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_data=(X_test, Y_test))\n",
        "\n",
        "# Terminer la session WandB\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "XSaV8u1OK4Tv",
        "outputId": "5ebe46c6-cb57-41be-d65a-b861c2204ee8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7733 - loss: 0.8586 - val_accuracy: 0.8557 - val_loss: 0.5755\n",
            "Epoch 2/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8535 - loss: 0.5782 - val_accuracy: 0.8557 - val_loss: 0.5826\n",
            "Epoch 3/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8464 - loss: 0.5972 - val_accuracy: 0.8557 - val_loss: 0.5804\n",
            "Epoch 4/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8405 - loss: 0.6106 - val_accuracy: 0.8557 - val_loss: 0.5812\n",
            "Epoch 5/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8541 - loss: 0.5681 - val_accuracy: 0.8557 - val_loss: 0.5830\n",
            "Epoch 6/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8511 - loss: 0.5757 - val_accuracy: 0.8557 - val_loss: 0.5832\n",
            "Epoch 7/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8622 - loss: 0.5429 - val_accuracy: 0.8557 - val_loss: 0.5883\n",
            "Epoch 8/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8391 - loss: 0.5970 - val_accuracy: 0.8557 - val_loss: 0.5793\n",
            "Epoch 9/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8570 - loss: 0.5517 - val_accuracy: 0.8557 - val_loss: 0.5890\n",
            "Epoch 10/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8472 - loss: 0.5853 - val_accuracy: 0.8557 - val_loss: 0.5888\n",
            "Epoch 11/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8477 - loss: 0.5712 - val_accuracy: 0.8557 - val_loss: 0.5814\n",
            "Epoch 12/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8480 - loss: 0.5660 - val_accuracy: 0.8557 - val_loss: 0.5851\n",
            "Epoch 13/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8505 - loss: 0.5544 - val_accuracy: 0.8557 - val_loss: 0.5895\n",
            "Epoch 14/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8349 - loss: 0.5860 - val_accuracy: 0.8557 - val_loss: 0.5858\n",
            "Epoch 15/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8439 - loss: 0.5639 - val_accuracy: 0.8557 - val_loss: 0.5904\n",
            "Epoch 16/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8494 - loss: 0.5398 - val_accuracy: 0.8557 - val_loss: 0.5940\n",
            "Epoch 17/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8489 - loss: 0.5427 - val_accuracy: 0.8557 - val_loss: 0.5998\n",
            "Epoch 18/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8520 - loss: 0.5289 - val_accuracy: 0.8557 - val_loss: 0.6022\n",
            "Epoch 19/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8424 - loss: 0.5483 - val_accuracy: 0.8557 - val_loss: 0.6059\n",
            "Epoch 20/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.5283 - val_accuracy: 0.8557 - val_loss: 0.6047\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">faithful-sunset-2</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/7gzk2n03' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/7gzk2n03</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_102355-7gzk2n03/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Archiver les modèles testés dans Weights and Biases**"
      ],
      "metadata": {
        "id": "eYJfy-tvSk48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder le modèle\n",
        "model.save('lstm_model.h5')\n",
        "\n",
        "# Initialiser une nouvelle session WandB pour l'archivage\n",
        "wandb.init(project=\"maintenance-predictive\", job_type=\"model_archiving\")\n",
        "\n",
        "# Archiver le modèle dans WandB\n",
        "wandb.save('lstm_model.h5')\n",
        "\n",
        "# Terminer la session WandB d'archivage\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "LcAjpKERS2Wh",
        "outputId": "e7d963df-6cff-4336-b51b-55fba43546d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250321_104231-4bwrsju3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/4bwrsju3' target=\"_blank\">sage-surf-3</a></strong> to <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/4bwrsju3' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/4bwrsju3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sage-surf-3</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/4bwrsju3' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/4bwrsju3</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_104231-4bwrsju3/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint # Import the correct callbacks\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Initialiser Weights and Biases\n",
        "wandb.init(project=\"maintenance-predictive\", config={\n",
        "    \"units\": 50,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 20,\n",
        "    \"window_size\": 10\n",
        "})\n",
        "\n",
        "# Construire le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(wandb.config.units, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.compile(optimizer=wandb.config.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle avec WandB\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=wandb.config.epochs,\n",
        "    batch_size=wandb.config.batch_size,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[WandbMetricsLogger(), WandbModelCheckpoint(filepath=\"lstm_model.h5\")] # Use the new callbacks\n",
        ")\n",
        "\n",
        "# Enregistrer le modèle\n",
        "model.save(\"lstm_model.h5\")\n",
        "wandb.save(\"lstm_model.h5\")\n",
        "\n",
        "# Terminer la session WandB\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hcuN962Zdfyc",
        "outputId": "bf107426-c3fe-4706-a263-cca671a811c8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7784 - loss: 0.8517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 15ms/step - accuracy: 0.7794 - loss: 0.8487 - val_accuracy: 0.8557 - val_loss: 0.5806\n",
            "Epoch 2/20\n",
            "\u001b[1m103/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8412 - loss: 0.6163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8417 - loss: 0.6147 - val_accuracy: 0.8557 - val_loss: 0.5798\n",
            "Epoch 3/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8484 - loss: 0.5856"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8484 - loss: 0.5857 - val_accuracy: 0.8557 - val_loss: 0.5850\n",
            "Epoch 4/20\n",
            "\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.6055"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8415 - loss: 0.6052 - val_accuracy: 0.8557 - val_loss: 0.5801\n",
            "Epoch 5/20\n",
            "\u001b[1m108/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8465 - loss: 0.5927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8465 - loss: 0.5926 - val_accuracy: 0.8557 - val_loss: 0.5833\n",
            "Epoch 6/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8515 - loss: 0.5728"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8514 - loss: 0.5729 - val_accuracy: 0.8557 - val_loss: 0.5886\n",
            "Epoch 7/20\n",
            "\u001b[1m104/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.5805"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8486 - loss: 0.5807 - val_accuracy: 0.8557 - val_loss: 0.5797\n",
            "Epoch 8/20\n",
            "\u001b[1m107/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8401 - loss: 0.6015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8403 - loss: 0.6008 - val_accuracy: 0.8557 - val_loss: 0.5812\n",
            "Epoch 9/20\n",
            "\u001b[1m103/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8502 - loss: 0.5776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8500 - loss: 0.5779 - val_accuracy: 0.8557 - val_loss: 0.5819\n",
            "Epoch 10/20\n",
            "\u001b[1m103/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8310 - loss: 0.6145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8321 - loss: 0.6120 - val_accuracy: 0.8557 - val_loss: 0.5798\n",
            "Epoch 11/20\n",
            "\u001b[1m106/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8478 - loss: 0.5733"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8478 - loss: 0.5735 - val_accuracy: 0.8557 - val_loss: 0.5884\n",
            "Epoch 12/20\n",
            "\u001b[1m108/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8476 - loss: 0.5672"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8475 - loss: 0.5674 - val_accuracy: 0.8557 - val_loss: 0.5863\n",
            "Epoch 13/20\n",
            "\u001b[1m107/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8407 - loss: 0.5884"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8409 - loss: 0.5877 - val_accuracy: 0.8557 - val_loss: 0.5919\n",
            "Epoch 14/20\n",
            "\u001b[1m105/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8450 - loss: 0.5716"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8452 - loss: 0.5714 - val_accuracy: 0.8557 - val_loss: 0.5814\n",
            "Epoch 15/20\n",
            "\u001b[1m106/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.5713"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8429 - loss: 0.5710 - val_accuracy: 0.8557 - val_loss: 0.5940\n",
            "Epoch 16/20\n",
            "\u001b[1m105/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8475 - loss: 0.5523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8474 - loss: 0.5528 - val_accuracy: 0.8557 - val_loss: 0.5919\n",
            "Epoch 17/20\n",
            "\u001b[1m102/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8554 - loss: 0.5288"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8548 - loss: 0.5309 - val_accuracy: 0.8557 - val_loss: 0.5959\n",
            "Epoch 18/20\n",
            "\u001b[1m108/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8605 - loss: 0.5193"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8601 - loss: 0.5202 - val_accuracy: 0.8557 - val_loss: 0.5935\n",
            "Epoch 19/20\n",
            "\u001b[1m104/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8562 - loss: 0.5260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8556 - loss: 0.5272 - val_accuracy: 0.8557 - val_loss: 0.5981\n",
            "Epoch 20/20\n",
            "\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8513 - loss: 0.5288"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8512 - loss: 0.5289 - val_accuracy: 0.8557 - val_loss: 0.5964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁███████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>▁▁▃▁▂▄▁▂▂▁▄▄▆▂▆▆▇▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.84712</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.53864</td></tr><tr><td>epoch/val_accuracy</td><td>0.85571</td></tr><tr><td>epoch/val_loss</td><td>0.59643</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">twilight-morning-6</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/xjv74k16' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/xjv74k16</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 40 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_112832-xjv74k16/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "Dyus7FdVTUDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluer les modèles**"
      ],
      "metadata": {
        "id": "AjWG4RgYTVfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "Y_pred = model.predict(X_test)\n",
        "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# Calculer les métriques\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred_classes)\n",
        "accuracy = accuracy_score(Y_test, Y_pred_classes)\n",
        "precision = precision_score(Y_test, Y_pred_classes, average='weighted')\n",
        "recall = recall_score(Y_test, Y_pred_classes, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8CDJnFTYAu",
        "outputId": "cfd4d8c4-c189-47a5-80e9-d99cb4d8f122"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Confusion Matrix:\n",
            " [[1281    0    0    0]\n",
            " [  63    0    0    0]\n",
            " [  67    0    0    0]\n",
            " [  86    0    0    0]]\n",
            "Accuracy: 0.8557114228456913\n",
            "Precision: 0.7322420391885976\n",
            "Recall: 0.8557114228456913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Initialiser WandB\n",
        "wandb.init(project=\"maintenance-predictive\", config={\n",
        "    \"model_type\": \"Random Forest\",\n",
        "    \"n_estimators\": 100,\n",
        "    \"random_state\": 42\n",
        "})\n",
        "\n",
        "# Enregistrer les métriques\n",
        "wandb.log({\n",
        "    \"accuracy\": accuracy_rf,\n",
        "    \"precision\": precision_rf,\n",
        "    \"recall\": recall_rf,\n",
        "    \"confusion_matrix\": conf_matrix_rf\n",
        "})\n",
        "\n",
        "# Terminer la session WandB\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "aDYCz4IJW78B",
        "outputId": "4c0e3ddb-d38b-4572-92e8-8d068f7fa653"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250321_105935-e1v0gvoq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/e1v0gvoq' target=\"_blank\">leafy-armadillo-4</a></strong> to <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/e1v0gvoq' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/e1v0gvoq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85571</td></tr><tr><td>precision</td><td>0.73224</td></tr><tr><td>recall</td><td>0.85571</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">leafy-armadillo-4</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/e1v0gvoq' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/e1v0gvoq</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_105935-e1v0gvoq/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Archivage des modèles**"
      ],
      "metadata": {
        "id": "JSmu33xoXE3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder le modèle Random Forest\n",
        "import joblib\n",
        "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
        "\n",
        "# Initialiser une nouvelle session WandB pour l'archivage\n",
        "wandb.init(project=\"maintenance-predictive\", job_type=\"model_archiving\")\n",
        "\n",
        "# Archiver dans WandB\n",
        "wandb.save('random_forest_model.pkl')\n",
        "\n",
        "# Terminer la session WandB d'archivage\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "PfYYM1p7XF3D",
        "outputId": "eafe049f-7e96-4de6-e3c8-c5ce0e0f633b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250321_110053-8pk8trab</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/8pk8trab' target=\"_blank\">lively-fire-5</a></strong> to <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/8pk8trab' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/8pk8trab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-fire-5</strong> at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/8pk8trab' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive/runs/8pk8trab</a><br> View project at: <a href='https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive' target=\"_blank\">https://wandb.ai/mohamedafdailat21-ecc/maintenance-predictive</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250321_110053-8pk8trab/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intégration applicative**"
      ],
      "metadata": {
        "id": "c-reJA7PTjQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intégrer le modèle dans une API Flask**"
      ],
      "metadata": {
        "id": "MB0iFGgFTkhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Charger le modèle\n",
        "model = tf.keras.models.load_model('lstm_model.h5')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Récupérer les données de la requête POST\n",
        "    data = request.json.get('data')\n",
        "\n",
        "    # Convertir les données en un tableau numpy\n",
        "    data = np.array(data)\n",
        "\n",
        "    # Vérifier que les données ont la bonne forme (10 pas de temps, 10 caractéristiques)\n",
        "    if data.shape != (10, 10):\n",
        "        return jsonify({\"error\": \"Les données doivent avoir la forme (10, 10)\"}), 400\n",
        "\n",
        "    # Redimensionner les données pour correspondre à l'entrée du modèle (1, 10, 10)\n",
        "    data = data.reshape(1, 10, 10)\n",
        "\n",
        "    # Faire la prédiction\n",
        "    prediction = model.predict(data)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "\n",
        "    # Retourner la prédiction\n",
        "    return jsonify({\"predicted_state\": int(predicted_class[0])})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8muZgbmjTnBF",
        "outputId": "b63c60b5-6a29-4266-dcb8-3d56f6253ce9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}